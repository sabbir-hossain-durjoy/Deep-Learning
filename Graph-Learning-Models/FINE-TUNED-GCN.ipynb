{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e82984",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torch-geometric scikit-learn tqdm seaborn matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from itertools import cycle\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "input_folder = \"/content/drive/MyDrive/defense/data/test\"\n",
    "output_path = \"/content/drive/MyDrive/defense/output\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=input_folder, transform=transform)\n",
    "class_names = dataset.classes\n",
    "\n",
    "feature_extractor = models.resnet18(pretrained=True)\n",
    "feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-1])\n",
    "feature_extractor.eval().to(device)\n",
    "\n",
    "features, labels = [], []\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(dataloader, desc='Extracting Features'):\n",
    "        images = images.to(device)\n",
    "        outputs = feature_extractor(images)\n",
    "        outputs = outputs.squeeze(-1).squeeze(-1)\n",
    "        features.append(outputs.cpu())\n",
    "        labels.append(targets.cpu())\n",
    "\n",
    "features = torch.cat(features).numpy()\n",
    "labels = torch.cat(labels).numpy()\n",
    "\n",
    "idx = np.arange(len(labels))\n",
    "idx_train, idx_test = train_test_split(idx, test_size=0.3, stratify=labels, random_state=42)\n",
    "idx_val, idx_test = train_test_split(idx_test, test_size=0.5, stratify=labels[idx_test], random_state=42)\n",
    "\n",
    "adj = kneighbors_graph(features, n_neighbors=7, metric='cosine', mode='connectivity', include_self=False)\n",
    "edge_index = torch.tensor(np.array(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(features, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(labels, dtype=torch.long)\n",
    ").to(device)\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim // 2)\n",
    "        self.conv3 = GCNConv(hidden_dim // 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.bn1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(model, name, patience=20, max_epochs=300):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.003, weight_decay=1e-4)\n",
    "    criterion = nn.NLLLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "    history = {\"train_loss\": [], \"val_loss\": [], \"test_loss\": [],\n",
    "               \"train_acc\": [], \"val_acc\": [], \"test_acc\": []}\n",
    "    best_val_acc, best_test_acc, best_epoch = 0, 0, 0\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[idx_train], data.y[idx_train])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "\n",
    "            losses = [\n",
    "                criterion(out[idx_train], data.y[idx_train]).item(),\n",
    "                criterion(out[idx_val], data.y[idx_val]).item(),\n",
    "                criterion(out[idx_test], data.y[idx_test]).item()\n",
    "            ]\n",
    "            accs = [\n",
    "                (pred[idx_train] == data.y[idx_train]).sum().item() / len(idx_train),\n",
    "                (pred[idx_val] == data.y[idx_val]).sum().item() / len(idx_val),\n",
    "                (pred[idx_test] == data.y[idx_test]).sum().item() / len(idx_test)\n",
    "            ]\n",
    "\n",
    "        history[\"train_loss\"].append(losses[0])\n",
    "        history[\"val_loss\"].append(losses[1])\n",
    "        history[\"test_loss\"].append(losses[2])\n",
    "        history[\"train_acc\"].append(accs[0])\n",
    "        history[\"val_acc\"].append(accs[1])\n",
    "        history[\"test_acc\"].append(accs[2])\n",
    "\n",
    "        if accs[1] > best_val_acc:\n",
    "            best_val_acc, best_test_acc, best_epoch = accs[1], accs[2], epoch\n",
    "            torch.save(model.state_dict(), os.path.join(output_path, f\"{name}_best.pth\"))\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch} | Train: {accs[0]:.4f} | Val: {accs[1]:.4f} | Test: {accs[2]:.4f}\")\n",
    "\n",
    "        if patience_counter > patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(output_path, f\"{name}_best.pth\")))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    cm = confusion_matrix(data.y[idx_test].cpu(), pred[idx_test].cpu())\n",
    "    report = classification_report(data.y[idx_test].cpu(), pred[idx_test].cpu(), target_names=class_names, output_dict=True)\n",
    "    return best_val_acc, best_test_acc, best_epoch, history, cm, pd.DataFrame(report).transpose(), out\n",
    "\n",
    "gcn_model = GCNModel(\n",
    "    input_dim=data.num_features,\n",
    "    hidden_dim=128,\n",
    "    output_dim=len(class_names)\n",
    ")\n",
    "\n",
    "best_val_acc, best_test_acc, best_epoch, history, cm, report, out = train_model(gcn_model, \"GCN_FT\")\n",
    "\n",
    "print(\"Best Epoch:\", best_epoch)\n",
    "print(\"Validation Accuracy:\", best_val_acc)\n",
    "print(\"Test Accuracy:\", best_test_acc)\n",
    "print(report)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
    "plt.title(\"Fine-tuned GCN Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.plot(epochs, history[\"test_loss\"], label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, history[\"train_acc\"], label=\"Train Acc\")\n",
    "plt.plot(epochs, history[\"val_acc\"], label=\"Val Acc\")\n",
    "plt.plot(epochs, history[\"test_acc\"], label=\"Test Acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_test = data.y[idx_test].cpu().numpy()\n",
    "y_score = F.softmax(out[idx_test], dim=1).cpu().numpy()\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, color=\"blue\", label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve for Positive Class\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
