{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569de3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torch-geometric scikit-learn tqdm python-docx seaborn matplotlib\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torchvision import datasets, transforms, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "input_folder = \"/content/drive/MyDrive/defense/data/test\"\n",
    "output_path = \"/content/drive/MyDrive/defense/output\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=input_folder, transform=transform)\n",
    "class_names = dataset.classes\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "feature_extractor = models.resnet18(pretrained=True)\n",
    "feature_extractor = nn.Sequential(*list(feature_extractor.children())[:-1])\n",
    "feature_extractor.eval().to(device)\n",
    "\n",
    "features, labels = [], []\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(dataloader, desc='Extracting Features'):\n",
    "        images = images.to(device)\n",
    "        outputs = feature_extractor(images)\n",
    "        outputs = outputs.squeeze(-1).squeeze(-1)\n",
    "        features.append(outputs.cpu())\n",
    "        labels.append(targets.cpu())\n",
    "\n",
    "features = torch.cat(features).numpy()\n",
    "labels = torch.cat(labels).numpy()\n",
    "print(\"Feature matrix shape:\", features.shape)\n",
    "\n",
    "idx = np.arange(len(labels))\n",
    "idx_train, idx_test = train_test_split(idx, test_size=0.3, stratify=labels, random_state=42)\n",
    "idx_val, idx_test = train_test_split(idx_test, test_size=0.5, stratify=labels[idx_test], random_state=42)\n",
    "\n",
    "adj = kneighbors_graph(features, n_neighbors=5, metric='cosine', mode='connectivity', include_self=False)\n",
    "edge_index = torch.tensor(np.array(adj.nonzero()), dtype=torch.long)\n",
    "\n",
    "data = Data(\n",
    "    x=torch.tensor(features, dtype=torch.float),\n",
    "    edge_index=edge_index,\n",
    "    y=torch.tensor(labels, dtype=torch.long)\n",
    ").to(device)\n",
    "\n",
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def train_model(model, name):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10)\n",
    "    criterion = nn.NLLLoss()\n",
    "    history = {k: [] for k in ['train_loss', 'val_loss', 'test_loss', 'train_acc', 'val_acc', 'test_acc']}\n",
    "    best_val_acc, best_test_acc, best_epoch = 0, 0, 0\n",
    "\n",
    "    for epoch in range(1, 201):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[idx_train], data.y[idx_train])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            losses = [criterion(out[i], data.y[i]).item() for i in [idx_train, idx_val, idx_test]]\n",
    "            accs = [(pred[i] == data.y[i]).sum().item() / len(i) for i in [idx_train, idx_val, idx_test]]\n",
    "\n",
    "        scheduler.step(accs[1])\n",
    "        for i, k in enumerate(history): history[k].append((losses + accs)[i])\n",
    "\n",
    "        if accs[1] > best_val_acc:\n",
    "            best_val_acc, best_test_acc, best_epoch = accs[1], accs[2], epoch\n",
    "            torch.save(model.state_dict(), os.path.join(output_path, f'{name}_best_model.pth'))\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"Epoch {epoch} | Train Acc: {accs[0]:.4f} | Val Acc: {accs[1]:.4f} | Test Acc: {accs[2]:.4f}\")\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join(output_path, f'{name}_best_model.pth')))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "\n",
    "    cm = confusion_matrix(data.y[idx_test].cpu(), pred[idx_test].cpu())\n",
    "    report = classification_report(data.y[idx_test].cpu(), pred[idx_test].cpu(), target_names=class_names, output_dict=True)\n",
    "    return best_val_acc, best_test_acc, best_epoch, history, cm, pd.DataFrame(report).transpose()\n",
    "\n",
    "gcn_model = GCNModel(\n",
    "    input_dim=data.num_features,\n",
    "    hidden_dim=64,\n",
    "    output_dim=len(class_names)\n",
    ")\n",
    "\n",
    "best_val_acc, best_test_acc, best_epoch, history, cm, report = train_model(gcn_model, \"GCN\")\n",
    "\n",
    "print(\"Best Epoch:\", best_epoch)\n",
    "print(\"Validation Accuracy:\", best_val_acc)\n",
    "print(\"Test Accuracy:\", best_test_acc)\n",
    "print(report)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
    "plt.title(\"GCN Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
