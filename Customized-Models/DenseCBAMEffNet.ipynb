{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "!pip install python-docx seaborn pillow timm --quiet\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub.utils._auth\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import timm\n",
    "import copy\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(\"Running on device:\", device)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "DATA_ROOT    = 'path'\n",
    "OUTPUT_DIR   = 'path'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE    = 32\n",
    "NUM_EPOCHS    = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "BEST_MODEL_PTH = os.path.join(OUTPUT_DIR, 'best_model.pth')\n",
    "BEST_ACC_TXT   = os.path.join(OUTPUT_DIR, 'best_val_acc.txt')\n",
    "CLF_TXT        = os.path.join(OUTPUT_DIR, 'classification_report.txt')\n",
    "CM_PNG         = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([0.485]*3, dtype=np.float32)\n",
    "        self.std  = np.array([0.229]*3, dtype=np.float32)\n",
    "    def __call__(self, img: Image.Image):\n",
    "        img = img.resize((224,224))\n",
    "        arr = np.array(img.convert('RGB'), dtype=np.float32) / 255.0\n",
    "        arr = (arr - self.mean) / self.std\n",
    "        return torch.from_numpy(arr).permute(2,0,1)\n",
    "\n",
    "transform = Transform()\n",
    "\n",
    "class AnnotDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.samples = []\n",
    "        self.classes = sorted(d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d)))\n",
    "        self.cl2i    = {c:i for i,c in enumerate(self.classes)}\n",
    "        for c in self.classes:\n",
    "            for fn in os.listdir(os.path.join(root, c)):\n",
    "                if fn.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append((os.path.join(root, c, fn), self.cl2i[c]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img), label\n",
    "\n",
    "full_ds = AnnotDataset(DATA_ROOT, transform)\n",
    "NUM_CLASSES = len(full_ds.classes)\n",
    "n = len(full_ds)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = n - n_train\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes//ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_planes//ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg = self.fc(self.avg_pool(x))\n",
    "        mx  = self.fc(self.max_pool(x))\n",
    "        return self.sigmoid(avg + mx)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2,1,kernel_size,padding=kernel_size//2,bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        mx,_ = torch.max(x, dim=1, keepdim=True)\n",
    "        feat = torch.cat([avg, mx], dim=1)\n",
    "        return self.sigmoid(self.conv(feat))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "class HybridDenseEff(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        densenet = timm.create_model('densenet121', pretrained=True)\n",
    "        self.dense_feats = nn.Sequential(densenet.features, nn.ReLU(inplace=False))\n",
    "        self.cbam        = CBAM(in_planes=1024)\n",
    "        eff = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "        eff.reset_classifier(0)\n",
    "        self.eff_feats = eff\n",
    "        fusion_dim = 1024 + self.eff_feats.num_features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        dn = self.dense_feats(x)\n",
    "        dn = self.cbam(dn)\n",
    "        dn = nn.functional.adaptive_avg_pool2d(dn,1).view(x.size(0), -1)\n",
    "        ef = self.eff_feats(x).view(x.size(0), -1)\n",
    "        fusion = torch.cat([dn, ef], dim=1)\n",
    "        return self.classifier(fusion)\n",
    "\n",
    "model = HybridDenseEff(NUM_CLASSES).to(device)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "opt   = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "best_val = 0.0\n",
    "best_wts = copy.deepcopy(model.state_dict())\n",
    "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"Starting epoch {epoch}/{NUM_EPOCHS}...\")\n",
    "    model.train()\n",
    "    tloss = tcorrect = tcount = 0\n",
    "    for x,y in train_ld:\n",
    "        logits = model(x)\n",
    "        loss   = crit(logits,y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        preds = logits.argmax(1)\n",
    "        tloss   += loss.item()*x.size(0)\n",
    "        tcorrect+= (preds==y).sum().item()\n",
    "        tcount  += y.size(0)\n",
    "    tl, ta = tloss/tcount, tcorrect/tcount\n",
    "\n",
    "    model.eval()\n",
    "    vloss = vcorrect = vcount = 0\n",
    "    all_y, all_p = [], []\n",
    "    with torch.no_grad():\n",
    "        for x,y in val_ld:\n",
    "            logits = model(x)\n",
    "            loss   = crit(logits,y)\n",
    "            preds  = logits.argmax(1)\n",
    "            vloss   += loss.item()*x.size(0)\n",
    "            vcorrect+= (preds==y).sum().item()\n",
    "            vcount  += y.size(0)\n",
    "            all_y.extend(y.numpy()); all_p.extend(preds.numpy())\n",
    "    vl, va = vloss/vcount, vcorrect/vcount\n",
    "\n",
    "    history['train_loss'].append(tl); history['train_acc'].append(ta)\n",
    "    history['val_loss'].append(vl);   history['val_acc'].append(va)\n",
    "    if va > best_val:\n",
    "        best_val = va\n",
    "        best_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_wts, BEST_MODEL_PTH)\n",
    "\n",
    "    print(f\"Epoch {epoch}/{NUM_EPOCHS} â†’ Train: {tl:.4f}/{ta:.4f}  Val: {vl:.4f}/{va:.4f}\")\n",
    "\n",
    "with open(BEST_ACC_TXT,'w') as f:\n",
    "    f.write(f\"{best_val:.4f}\\n\")\n",
    "\n",
    "plt.figure(); plt.plot(history['train_loss'], label='Train Loss'); plt.plot(history['val_loss'], label='Val Loss'); plt.legend(); plt.savefig(os.path.join(OUTPUT_DIR,'loss_curve.png')); plt.close()\n",
    "plt.figure(); plt.plot(history['train_acc'], label='Train Acc'); plt.plot(history['val_acc'], label='Val Acc'); plt.legend(); plt.savefig(os.path.join(OUTPUT_DIR,'acc_curve.png')); plt.close()\n",
    "\n",
    "model.load_state_dict(best_wts)\n",
    "cm = confusion_matrix(all_y, all_p)\n",
    "plt.figure(figsize=(6,5)); sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=full_ds.classes, yticklabels=full_ds.classes); plt.savefig(CM_PNG); plt.close()\n",
    "\n",
    "rep = classification_report(all_y, all_p, target_names=full_ds.classes)\n",
    "with open(CLF_TXT,'w') as f:\n",
    "    f.write(rep)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading('Pneumonia Detection Report', level=1)\n",
    "doc.add_paragraph(f\"Best Validation Accuracy: {best_val:.4f}\")\n",
    "doc.add_heading('Confusion Matrix', level=2); doc.add_picture(CM_PNG, width=Inches(5))\n",
    "doc.add_heading('Classification Report', level=2); doc.add_paragraph(rep)\n",
    "doc.add_heading('Training/Validation Curves', level=2); doc.add_picture(os.path.join(OUTPUT_DIR,'loss_curve.png'), width=Inches(5)); doc.add_picture(os.path.join(OUTPUT_DIR,'acc_curve.png'), width=Inches(5))\n",
    "doc.save(os.path.join(OUTPUT_DIR,'report.docx'))\n",
    "\n",
    "print(\" Done! All outputs in\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
