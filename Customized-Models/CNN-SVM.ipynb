{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc001f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "!pip install python-docx seaborn pillow scikit-learn joblib --quiet\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "device = torch.device('cpu')\n",
    "print(\"Running on device:\", device)\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_ROOT  = 'path'\n",
    "OUTPUT_DIR = 'path'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "BEST_ACC_TXT   = os.path.join(OUTPUT_DIR, 'cnn_svm_best_val_acc.txt')\n",
    "CLF_TXT        = os.path.join(OUTPUT_DIR, 'cnn_svm_classification_report.txt')\n",
    "CM_PNG         = os.path.join(OUTPUT_DIR, 'cnn_svm_confusion_matrix.png')\n",
    "REPORT_DOCX    = os.path.join(OUTPUT_DIR, 'cnn_svm_report.docx')\n",
    "\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([0.485]*3, dtype=np.float32)\n",
    "        self.std  = np.array([0.229]*3, dtype=np.float32)\n",
    "    def __call__(self, img: Image.Image):\n",
    "        img = img.resize((224,224))\n",
    "        arr = np.array(img.convert('RGB'), dtype=np.float32)/255.0\n",
    "        arr = (arr - self.mean)/self.std\n",
    "        return torch.from_numpy(arr).permute(2,0,1)\n",
    "\n",
    "transform = Transform()\n",
    "\n",
    "class AnnotDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.samples = []\n",
    "        self.classes = sorted(d for d in os.listdir(root) if os.path.isdir(os.path.join(root,d)))\n",
    "        self.cl2i    = {c:i for i,c in enumerate(self.classes)}\n",
    "        for c in self.classes:\n",
    "            for fn in os.listdir(os.path.join(root,c)):\n",
    "                if fn.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                    self.samples.append((os.path.join(root,c,fn), self.cl2i[c]))\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        p,l = self.samples[idx]\n",
    "        img = Image.open(p)\n",
    "        return self.transform(img), l\n",
    "\n",
    "full_ds = AnnotDataset(DATA_ROOT, transform)\n",
    "NUM_CLASSES = len(full_ds.classes)\n",
    "n = len(full_ds)\n",
    "n_train = int(0.8*n)\n",
    "n_val   = n - n_train\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.f = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(128,256,3,padding=1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(256,512,3,padding=1), nn.BatchNorm2d(512), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.f(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "cnn = SimpleCNN().cpu()\n",
    "cnn.eval()\n",
    "\n",
    "def extract_features(dataloader, model):\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            f = model(x).numpy()\n",
    "            feats.append(f)\n",
    "            labels.append(y.numpy())\n",
    "    return np.vstack(feats), np.concatenate(labels)\n",
    "\n",
    "print(\"Extracting CNN features...\")\n",
    "train_feats, train_lbls = extract_features(train_ld, cnn)\n",
    "val_feats, val_lbls = extract_features(val_ld, cnn)\n",
    "print(\"Train features:\", train_feats.shape, \"Val features:\", val_feats.shape)\n",
    "\n",
    "print(\"Training SVM classifier...\")\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True)\n",
    "svm.fit(train_feats, train_lbls)\n",
    "\n",
    "svm_acc = svm.score(val_feats, val_lbls)\n",
    "print(f\"Validation Accuracy: {svm_acc:.4f}\")\n",
    "\n",
    "dump(svm, os.path.join(OUTPUT_DIR, 'cnn_svm_model.joblib'))\n",
    "\n",
    "with open(BEST_ACC_TXT,'w') as f: f.write(f\"{svm_acc:.4f}\\n\")\n",
    "\n",
    "print(\"Evaluating model...\")\n",
    "preds = svm.predict(val_feats)\n",
    "cm = confusion_matrix(val_lbls, preds)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=full_ds.classes, yticklabels=full_ds.classes)\n",
    "plt.title(\"CNN+SVM Confusion Matrix\")\n",
    "plt.savefig(CM_PNG); plt.close()\n",
    "\n",
    "rep = classification_report(val_lbls, preds, target_names=full_ds.classes)\n",
    "with open(CLF_TXT,'w') as f: f.write(rep)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_heading('CNN+SVM Pneumonia Detection Report', level=1)\n",
    "doc.add_paragraph(f\"Validation Accuracy: {svm_acc:.4f}\")\n",
    "doc.add_heading('Confusion Matrix', level=2)\n",
    "doc.add_picture(CM_PNG, width=Inches(5))\n",
    "doc.add_heading('Classification Report', level=2)\n",
    "doc.add_paragraph(rep)\n",
    "doc.save(REPORT_DOCX)\n",
    "\n",
    "print(\"âœ… Done! All CNN+SVM outputs saved in:\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
