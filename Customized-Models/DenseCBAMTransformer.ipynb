{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd5479",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ─── DISABLE CUDA ENTIRELY ───────────────────────────────────────────────\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"   # hide all GPUs\n",
    "print(\"CUDA_VISIBLE_DEVICES =\", os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "# ─── INSTALL DEPENDENCIES ────────────────────────────────────────────────\n",
    "!pip install python-docx seaborn pillow timm --quiet\n",
    "\n",
    "# ─── MOUNT GOOGLE DRIVE (COLAB ONLY) ────────────────────────────────────\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ─── STANDARD IMPORTS ───────────────────────────────────────────────────\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=UserWarning,\n",
    "    module=\"huggingface_hub.utils._auth\"\n",
    ")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import timm\n",
    "import copy\n",
    "\n",
    "# ─── FORCE CPU ───────────────────────────────────────────────────────────\n",
    "device = torch.device('cpu')\n",
    "print(\"Running on device:\", device)\n",
    "\n",
    "# ─── SEED ────────────────────────────────────────────────────────────────\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# ─── USER CONFIGURATION ─────────────────────────────────────────────────\n",
    "DATA_ROOT    = '/content/drive/MyDrive/dp/data'    # data folder: one subdir per class\n",
    "OUTPUT_DIR   = '/content/drive/MyDrive/dp/output'  # where to save outputs\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE    = 32\n",
    "NUM_EPOCHS    = 2\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "BEST_MODEL_PTH = os.path.join(OUTPUT_DIR, 'best_model.pth')\n",
    "BEST_ACC_TXT   = os.path.join(OUTPUT_DIR, 'best_val_acc.txt')\n",
    "CLF_TXT        = os.path.join(OUTPUT_DIR, 'classification_report.txt')\n",
    "CM_PNG         = os.path.join(OUTPUT_DIR, 'confusion_matrix.png')\n",
    "\n",
    "# ─── TRANSFORM ───────────────────────────────────────────────────────────\n",
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.mean = np.array([0.485]*3, dtype=np.float32)\n",
    "        self.std  = np.array([0.229]*3, dtype=np.float32)\n",
    "    def __call__(self, img: Image.Image):\n",
    "        img = img.resize((224,224))\n",
    "        arr = np.array(img.convert('RGB'), dtype=np.float32) / 255.0\n",
    "        arr = (arr - self.mean) / self.std\n",
    "        return torch.from_numpy(arr).permute(2,0,1)\n",
    "\n",
    "transform = Transform()\n",
    "\n",
    "# ─── DATASET ─────────────────────────────────────────────────────────────\n",
    "class AnnotDataset(Dataset):\n",
    "    def __init__(self, root, transform):\n",
    "        self.samples = []\n",
    "        self.classes = sorted(d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d)))\n",
    "        self.cl2i = {c: i for i, c in enumerate(self.classes)}\n",
    "        for c in self.classes:\n",
    "            folder = os.path.join(root, c)\n",
    "            for fn in os.listdir(folder):\n",
    "                if fn.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    self.samples.append((os.path.join(folder, fn), self.cl2i[c]))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        img = Image.open(path)\n",
    "        return self.transform(img), label\n",
    "\n",
    "full_ds = AnnotDataset(DATA_ROOT, transform)\n",
    "NUM_CLASSES = len(full_ds.classes)\n",
    "n = len(full_ds)\n",
    "n_train = int(0.8 * n)\n",
    "n_val   = n - n_train\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val])\n",
    "train_ld = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_ld   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ─── CBAM MODULE ──────────────────────────────────────────────────────────\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, in_planes//ratio, 1, bias=False),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_planes//ratio, in_planes, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = self.fc(self.avg_pool(x))\n",
    "        mx  = self.fc(self.max_pool(x))\n",
    "        return self.sigmoid(avg + mx)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg = torch.mean(x, dim=1, keepdim=True)\n",
    "        mx, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        feat = torch.cat([avg, mx], dim=1)\n",
    "        return self.sigmoid(self.conv(feat))\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.ca = ChannelAttention(in_planes, ratio)\n",
    "        self.sa = SpatialAttention(kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x * self.ca(x)\n",
    "        x = x * self.sa(x)\n",
    "        return x\n",
    "\n",
    "# ─── HYBRID MODEL: DenseNet-121 + CBAM + Transformer Decoder ────────────\n",
    "class HybridDenseDecoder(nn.Module):\n",
    "    def __init__(self, num_classes, hid_dim=1024, nhead=8, num_layers=3):\n",
    "        super().__init__()\n",
    "        # 1) DenseNet-121 backbone (features only)\n",
    "        densenet = timm.create_model('densenet121', pretrained=True)\n",
    "        self.features = densenet.features\n",
    "        self.cbam     = CBAM(in_planes=1024)\n",
    "\n",
    "        # 2) Transformer Decoder\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hid_dim,\n",
    "            nhead=nhead,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # learned query vector of shape [1, hid_dim]\n",
    "        self.query = nn.Parameter(torch.zeros(1, hid_dim))\n",
    "\n",
    "        # 3) classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hid_dim, 512),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.features(x)           # [B, C=1024, H', W']\n",
    "        feat = self.cbam(feat)\n",
    "        B, C, H, W = feat.shape\n",
    "\n",
    "        src = feat.view(B, C, H*W).permute(0, 2, 1)  # [B, S=H*W, C]\n",
    "        tgt = self.query.unsqueeze(0).expand(B, 1, -1)  # [B,1,C]\n",
    "\n",
    "        dec_out = self.transformer_decoder(tgt, src)  # [B,1,C]\n",
    "        dec_out = dec_out.squeeze(1)                   # [B, C]\n",
    "        return self.classifier(dec_out)\n",
    "\n",
    "# Instantiate\n",
    "model = HybridDenseDecoder(NUM_CLASSES).to(device)\n",
    "crit  = nn.CrossEntropyLoss()\n",
    "opt   = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# ─── TRAIN & VALIDATE ─────────────────────────────────────────────────────\n",
    "best_val = 0.0\n",
    "best_wts = copy.deepcopy(model.state_dict())\n",
    "history  = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "all_y, all_p = [], []\n",
    "\n",
    "print(f\"Starting training for {NUM_EPOCHS} epochs…\")\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    print(f\"→ Epoch {epoch}/{NUM_EPOCHS}\")  # epoch print\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "    tloss = tcorrect = tcount = 0\n",
    "    for x, y in train_ld:\n",
    "        logits = model(x)\n",
    "        loss   = crit(logits, y)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        preds = logits.argmax(1)\n",
    "        tloss   += loss.item() * x.size(0)\n",
    "        tcorrect+= (preds == y).sum().item()\n",
    "        tcount  += y.size(0)\n",
    "    tl, ta = tloss / tcount, tcorrect / tcount\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    vloss = vcorrect = vcount = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_ld:\n",
    "            logits = model(x)\n",
    "            loss   = crit(logits, y)\n",
    "            preds  = logits.argmax(1)\n",
    "            vloss   += loss.item() * x.size(0)\n",
    "            vcorrect+= (preds == y).sum().item()\n",
    "            vcount  += y.size(0)\n",
    "            all_y.extend(y.numpy()); all_p.extend(preds.numpy())\n",
    "    vl, va = vloss / vcount, vcorrect / vcount\n",
    "\n",
    "    history['train_loss'].append(tl)\n",
    "    history['train_acc'].append(ta)\n",
    "    history['val_loss'].append(vl)\n",
    "    history['val_acc'].append(va)\n",
    "    if va > best_val:\n",
    "        best_val = va\n",
    "        best_wts = copy.deepcopy(model.state_dict())\n",
    "        torch.save(best_wts, BEST_MODEL_PTH)\n",
    "\n",
    "    print(f\"   Train: {tl:.4f}/{ta:.4f}, Val: {vl:.4f}/{va:.4f}\")\n",
    "\n",
    "# ─── SAVE METRICS & PLOTS ───────────────────────────────────────────────\n",
    "with open(BEST_ACC_TXT, 'w') as f:\n",
    "    f.write(f\"{best_val:.4f}\\n\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'],   label='Val Loss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'loss_curve.png'))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history['train_acc'],  label='Train Acc')\n",
    "plt.plot(history['val_acc'],    label='Val Acc')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'acc_curve.png'))\n",
    "plt.close()\n",
    "\n",
    "model.load_state_dict(best_wts)\n",
    "cm = confusion_matrix(all_y, all_p)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=full_ds.classes,\n",
    "            yticklabels=full_ds.classes)\n",
    "plt.savefig(CM_PNG)\n",
    "plt.close()\n",
    "\n",
    "rep = classification_report(all_y, all_p, target_names=full_ds.classes)\n",
    "with open(CLF_TXT, 'w') as f:\n",
    "    f.write(rep)\n",
    "\n",
    "# ─── WORD REPORT ─────────────────────────────────────────────────────────\n",
    "doc = Document()\n",
    "doc.add_heading('Detection Report', level=1)\n",
    "doc.add_paragraph(f\"Best Validation Accuracy: {best_val:.4f}\")\n",
    "doc.add_heading('Confusion Matrix', level=2)\n",
    "doc.add_picture(CM_PNG, width=Inches(5))\n",
    "doc.add_heading('Classification Report', level=2)\n",
    "doc.add_paragraph(rep)\n",
    "doc.add_heading('Training/Validation Curves', level=2)\n",
    "doc.add_picture(os.path.join(OUTPUT_DIR, 'loss_curve.png'), width=Inches(5))\n",
    "doc.add_picture(os.path.join(OUTPUT_DIR, 'acc_curve.png'),  width=Inches(5))\n",
    "doc.save(os.path.join(OUTPUT_DIR, 'report.docx'))\n",
    "\n",
    "print(\" Done! All outputs in\", OUTPUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
